name: Production-Grade Deploy

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  infra-and-deploy:
    name: Provision & Deploy to Production
    runs-on: ubuntu-latest
    environment:
      name: prod
      url: https://nexus-sus-alb-prod-XXXXX.us-east-1.elb.amazonaws.com
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Clean Cache
        run: |
          rm -rf infra/.terraform
          rm -rf infra/.terraform.lock.hcl
          rm -rf infra/terraform.tfstate*
          rm -rf ~/.terraform*
          echo "✅ Cache limpo"

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Backup State
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          aws s3 cp s3://nexus-sus-terraform-state/prod/terraform.tfstate \
            s3://nexus-sus-terraform-state/prod/terraform.tfstate.backup.$(date +%s) || true
          echo "✅ State backed up"

      - name: Import Existing Resources
        working-directory: infra
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_environment: prod
          TF_VAR_db_username: nexus_admin
          TF_VAR_admin_password: ${{ secrets.DB_PASSWORD }}
        run: |
          terraform init \
            -backend-config="bucket=nexus-sus-terraform-state" \
            -backend-config="key=prod/terraform.tfstate" \
            -backend-config="region=us-east-1" \
            -backend-config="dynamodb_table=nexus-sus-terraform-locks"
          
          # Remover VPC antiga do state (não deleta da AWS, só desvincula)
          terraform state rm aws_vpc.main || true
          
          terraform import aws_iam_policy.etl_s3_read arn:aws:iam::629614691528:policy/nexus-sus-etl-s3-read-policy-prod || true
          terraform import aws_iam_policy.etl_s3_write arn:aws:iam::629614691528:policy/nexus-sus-etl-s3-write-policy-prod || true
          terraform import aws_iam_policy.etl_ecr_access arn:aws:iam::629614691528:policy/nexus-sus-etl-ecr-access-policy-prod || true
          terraform import aws_iam_policy.ecs_logging arn:aws:iam::629614691528:policy/nexus-sus-ecs-logging-policy-prod || true
          
          # Import Lambda
          terraform import aws_lambda_function.etl nexus-sus-etl-prod || true
          
          echo "✅ All resources imported"

      - name: Terraform Plan
        working-directory: infra
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_environment: prod
          TF_VAR_db_username: nexus_admin
          TF_VAR_admin_password: ${{ secrets.DB_PASSWORD }}
        run: |
          terraform plan -var-file="prod.tfvars" -out=tfplan
          echo "✅ Plan successful"

      - name: Terraform Apply
        working-directory: infra
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_environment: prod
          TF_VAR_db_username: nexus_admin
          TF_VAR_admin_password: ${{ secrets.DB_PASSWORD }}
        run: |
          terraform apply -auto-approve tfplan
          echo "✅ Apply successful - Production is LIVE!"

      - name: Validate Deployment
        run: |
          echo "✅ Deployment complete"
          echo "Check your application at the ALB endpoint in AWS Console"

      - name: Build ETL Lambda Function
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          # 1. Criar estrutura de diretórios
          mkdir -p etl-package/python/lib/python3.11/site-packages
          mkdir -p etl-code
          
          # 2. Instalar dependências
          pip install -r nexus-sus-etl/requirements.txt -t etl-package/python/lib/python3.11/site-packages/
          
          # 3. Copiar código
          cp nexus-sus-etl/extrair_sus.py etl-code/
          cp nexus-sus-etl/create_table.sql etl-code/
          
          # 4. Zipar código da função
          cd etl-code
          zip -r ../etl-function.zip .
          cd ..
          
          # 5. Zipar layer de dependências
          cd etl-package
          zip -r ../etl-layer.zip python/
          cd ..
          
          # 6. Upload código pra Lambda
          aws lambda update-function-code \
            --function-name nexus-sus-etl-prod \
            --zip-file fileb://etl-function.zip
          
          # 7. Upload layer pro S3 (bypass do limite de 70MB)
          aws s3 cp etl-layer.zip s3://nexus-sus-data-lake-prod/lambda-layers/etl-layer.zip
          
          # 8. Publicar layer a partir do S3
          LAYER_ARN=$(aws lambda publish-layer-version \
            --layer-name nexus-sus-etl-dependencies-prod \
            --content S3Bucket=nexus-sus-data-lake-prod,S3Key=lambda-layers/etl-layer.zip \
            --compatible-runtimes python3.11 \
            --query 'LayerVersionArn' --output text)
          
          # 9. Atualizar Lambda pra usar o layer
          aws lambda update-function-configuration \
            --function-name nexus-sus-etl-prod \
            --layers "$LAYER_ARN"
          
          echo "✅ ETL Lambda updated with code and dependencies"

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build, Tag and Push Images
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        run: |
          docker build -t $ECR_REGISTRY/nexus-sus-api-prod:latest -f api/Dockerfile .
          docker push $ECR_REGISTRY/nexus-sus-api-prod:latest
          
          docker build -t $ECR_REGISTRY/nexus-sus-frontend-prod:latest ./nexus-sus-frontend
          docker push $ECR_REGISTRY/nexus-sus-frontend-prod:latest

      - name: Update ECS Services
        run: |
          aws ecs update-service --cluster nexus-sus-cluster-prod --service nexus-sus-api-service-prod --force-new-deployment
          aws ecs update-service --cluster nexus-sus-cluster-prod --service nexus-sus-frontend-service-prod --force-new-deployment
